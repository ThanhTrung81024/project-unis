import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Tuple
import os
from datetime import datetime
import json
import traceback
from utils.helpers import generate_id, get_timestamp, ensure_dir, save_json, get_data_paths

class DataService:
    def __init__(self):
        self.paths = get_data_paths()
        # Ensure all directories exist
        for path in self.paths.values():
            ensure_dir(path)
        
    def process_raw_data(self, file_path: str) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω d·ªØ li·ªáu th√¥ t·ª´ file Excel/CSV
        D·ª±a tr√™n c·∫•u tr√∫c d·ªØ li·ªáu th·ª±c t·∫ø: DocDate, BranchCode0, BranchName0, CustomerCode, ItemCode, ItemName, Quantity, Unit
        """
        try:
            print(f"üìñ Reading file: {file_path}")
            
            # ƒê·ªçc file d·ªØ li·ªáu
            if file_path.endswith('.xlsx'):
                print("üìä Reading Excel file...")
                df = pd.read_excel(file_path)
            elif file_path.endswith('.csv'):
                print("üìä Reading CSV file...")
                df = pd.read_csv(file_path)
            else:
                raise ValueError("Unsupported file format")
            
            print(f"‚úÖ File read successfully. Shape: {df.shape}")
            print(f"üìã Columns: {list(df.columns)}")
            
            # Ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu th·ª±c t·∫ø
            expected_columns = [
                'DocDate',           # Ng√†y ch·ª©ng t·ª´
                'BranchCode0',       # M√£ chi nh√°nh
                'BranchName0',       # T√™n chi nh√°nh
                'CustomerCode',      # M√£ kh√°ch h√†ng
                'ItemCode',          # M√£ h√†ng
                'ItemName',          # T√™n h√†ng
                'Quantity',          # S·ªë l∆∞·ª£ng
                'Unit'               # ƒê∆°n v·ªã
            ]
            
            # Ki·ªÉm tra xem c√≥ ƒë·ªß c·ªôt c·∫ßn thi·∫øt kh√¥ng
            missing_columns = [col for col in expected_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"Thi·∫øu c√°c c·ªôt: {missing_columns}. C√°c c·ªôt c√≥ s·∫µn: {list(df.columns)}")
            
            # Ch·ªâ gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt
            df_v = df[expected_columns].copy()
            print(f"‚úÖ Filtered columns. Shape: {df_v.shape}")
            
            # X·ª≠ l√Ω d·ªØ li·ªáu
            df_v = df_v.dropna().reset_index(drop=True)
            print(f"‚úÖ Removed null values. Shape: {df_v.shape}")
            
            # Chu·∫©n h√≥a ƒë∆°n v·ªã v√† ItemCode
            df_v['Unit'] = df_v['Unit'].astype(str).str.lower()
            df_v['ItemCode'] = df_v['ItemCode'].astype(str).str.strip()
            
            # L·ªçc theo ƒëi·ªÅu ki·ªán: ch·ªâ gi·ªØ 'vi√™n' v√† ItemCode kh√°c 'VANCHUYEN'
            df_v_filtered = df_v[(df_v['Unit'] == 'vi√™n') & (df_v['ItemCode'] != 'VANCHUYEN')].copy()
            print(f"‚úÖ Filtered by unit and item code. Shape: {df_v_filtered.shape}")
            
            # L·ªçc h√†ng b√°n (Quantity > 0)
            df_pos = df_v_filtered[df_v_filtered['Quantity'] > 0].copy()
            print(f"‚úÖ Filtered positive quantities. Shape: {df_pos.shape}")
            
            # G·ªôp d·ªØ li·ªáu theo ItemCode v√† DocDate
            df_grouped = (
                df_pos.groupby(['ItemCode', 'DocDate'], as_index=False)
                .agg({'Quantity': 'sum'})
            )
            print(f"‚úÖ Grouped by ItemCode and DocDate. Shape: {df_grouped.shape}")
            
            # ƒê·∫£m b·∫£o DocDate l√† datetime tr∆∞·ªõc khi s·∫Øp x·∫øp
            if not pd.api.types.is_datetime64_any_dtype(df_grouped['DocDate']):
                df_grouped['DocDate'] = pd.to_datetime(df_grouped['DocDate'], errors='coerce')
                df_grouped = df_grouped.dropna(subset=['DocDate'])
            print(f"‚úÖ DocDate is datetime. Shape: {df_grouped.shape}")
            
            # S·∫Øp x·∫øp theo th·ªùi gian
            df_grouped = df_grouped.sort_values('DocDate').reset_index(drop=True)
            
            # Lo·∫°i b·ªè s·∫£n ph·∫©m b√°n √≠t ng√†y
            day_counts = df_grouped.groupby('ItemCode')['DocDate'].nunique()
            few_day_products = day_counts[day_counts <= 5].index
            df_grouped = df_grouped[~df_grouped['ItemCode'].isin(few_day_products)].copy()
            print(f"‚úÖ Removed products with <= 5 days. Shape: {df_grouped.shape}")
            
            # T·∫°o d·ªØ li·ªáu theo tu·∫ßn
            df_grouped['week_start'] = df_grouped['DocDate'].dt.to_period('W').apply(lambda r: r.start_time)
            
            weekly_demand = (
                df_grouped
                .groupby(['ItemCode', 'week_start'], as_index=False)
                .agg({'Quantity': 'sum'})
            )
            
            weekly_demand.columns = ['ItemCode', 'Week', 'TotalQuantity']
            weekly_demand = weekly_demand.sort_values(by=['ItemCode', 'Week']).reset_index(drop=True)
            print(f"‚úÖ Created weekly demand data. Shape: {weekly_demand.shape}")
            
            # L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√†o th∆∞ m·ª•c processed
            processed_file = f"{self.paths['processed']}/weekly_demand_{generate_id()}.csv"
            weekly_demand.to_csv(processed_file, index=False, encoding="utf-8-sig")
            print(f"‚úÖ Saved processed data to: {processed_file}")
            
            # T·∫°o th·ªëng k√™
            stats = {
                "total_products": len(weekly_demand['ItemCode'].unique()),
                "total_weeks": len(weekly_demand['Week'].unique()),
                "total_records": len(weekly_demand),
                "date_range": {
                    "start": weekly_demand['Week'].min().strftime('%Y-%m-%d'),
                    "end": weekly_demand['Week'].max().strftime('%Y-%m-%d')
                },
                "processed_file": processed_file
            }
            
            print(f"‚úÖ Processing completed. Stats: {stats}")
            
            return {
                "success": True,
                "data": weekly_demand.to_dict('records'),
                "stats": stats,
                "processed_file": processed_file
            }
            
        except Exception as e:
            print(f"‚ùå Error in process_raw_data: {str(e)}")
            print(f"üìã Traceback: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_data_summary(self, data: pd.DataFrame) -> Dict[str, Any]:
        """T·∫°o t√≥m t·∫Øt d·ªØ li·ªáu"""
        summary = {
            "total_products": len(data['ItemCode'].unique()),
            "total_weeks": len(data['Week'].unique()),
            "date_range": {
                "start": data['Week'].min().strftime('%Y-%m-%d'),
                "end": data['Week'].max().strftime('%Y-%m-%d')
            },
            "quantity_stats": {
                "mean": float(data['TotalQuantity'].mean()),
                "std": float(data['TotalQuantity'].std()),
                "min": float(data['TotalQuantity'].min()),
                "max": float(data['TotalQuantity'].max())
            }
        }
        return summary
    
    def create_visualization(self, data: pd.DataFrame, product_code: str = None) -> str:
        """T·∫°o bi·ªÉu ƒë·ªì cho d·ªØ li·ªáu"""
        try:
            plt.figure(figsize=(12, 6))
            
            if product_code:
                # Bi·ªÉu ƒë·ªì cho 1 s·∫£n ph·∫©m
                product_data = data[data['ItemCode'] == product_code]
                plt.plot(product_data['Week'], product_data['TotalQuantity'], marker='o')
                plt.title(f'Demand Forecast - {product_code}')
            else:
                # Bi·ªÉu ƒë·ªì t·ªïng h·ª£p
                for item in data['ItemCode'].unique()[:10]:  # Ch·ªâ v·∫Ω 10 s·∫£n ph·∫©m ƒë·∫ßu
                    item_data = data[data['ItemCode'] == item]
                    plt.plot(item_data['Week'], item_data['TotalQuantity'], marker='o', label=str(item))
                plt.title('Demand Forecast - Top 10 Products')
                plt.legend()
            
            plt.xlabel('Week')
            plt.ylabel('Total Quantity')
            plt.xticks(rotation=45)
            plt.grid(True)
            plt.tight_layout()
            
            # L∆∞u bi·ªÉu ƒë·ªì v√†o th∆∞ m·ª•c plots
            plot_file = f"{self.paths['storage']}/plots/plot_{generate_id()}.png"
            ensure_dir(os.path.dirname(plot_file))
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            return plot_file
            
        except Exception as e:
            print(f"‚ùå Error in create_visualization: {str(e)}")
            raise
    
    def load_raw_data(self, filename: str) -> pd.DataFrame:
        """Load d·ªØ li·ªáu g·ªëc t·ª´ th∆∞ m·ª•c raw"""
        file_path = os.path.join(self.paths['raw'], filename)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")
        
        if filename.endswith('.xlsx'):
            return pd.read_excel(file_path)
        elif filename.endswith('.csv'):
            return pd.read_csv(file_path)
        else:
            raise ValueError("Unsupported file format")
    
    def save_processed_data(self, data: pd.DataFrame, filename: str) -> str:
        """L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√†o th∆∞ m·ª•c processed"""
        file_path = os.path.join(self.paths['processed'], filename)
        data.to_csv(file_path, index=False, encoding="utf-8-sig")
        return file_path
    
    def list_raw_files(self) -> List[str]:
        """Li·ªát k√™ c√°c file d·ªØ li·ªáu g·ªëc"""
        raw_dir = self.paths['raw']
        if not os.path.exists(raw_dir):
            return []
        
        files = []
        for file in os.listdir(raw_dir):
            if file.endswith(('.xlsx', '.csv')):
                files.append(file)
        return files
    
    def list_processed_files(self) -> List[str]:
        """Li·ªát k√™ c√°c file d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"""
        processed_dir = self.paths['processed']
        if not os.path.exists(processed_dir):
            return []
        
        files = []
        for file in os.listdir(processed_dir):
            if file.endswith('.csv'):
                files.append(file)
        return files
