#!/usr/bin/env python3
"""
Debug script Ä‘á»ƒ kiá»ƒm tra xá»­ lÃ½ dá»¯ liá»‡u
"""

import pandas as pd
import numpy as np
import os
import traceback

def debug_data_processing():
    """Debug quÃ¡ trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u"""
    
    file_path = "data/raw/UNIS_ORDER.xlsx"
    
    try:
        print(f"ğŸ“– Reading file: {file_path}")
        
        # Äá»c file dá»¯ liá»‡u
        df = pd.read_excel(file_path)
        print(f"âœ… File read successfully. Shape: {df.shape}")
        print(f"ğŸ“‹ Columns: {list(df.columns)}")
        
        # Kiá»ƒm tra cáº¥u trÃºc dá»¯ liá»‡u thá»±c táº¿
        expected_columns = [
            'DocDate',           # NgÃ y chá»©ng tá»«
            'BranchCode0',       # MÃ£ chi nhÃ¡nh
            'BranchName0',       # TÃªn chi nhÃ¡nh
            'CustomerCode',      # MÃ£ khÃ¡ch hÃ ng
            'ItemCode',          # MÃ£ hÃ ng
            'ItemName',          # TÃªn hÃ ng
            'Quantity',          # Sá»‘ lÆ°á»£ng
            'Unit'               # ÄÆ¡n vá»‹
        ]
        
        # Kiá»ƒm tra xem cÃ³ Ä‘á»§ cá»™t cáº§n thiáº¿t khÃ´ng
        missing_columns = [col for col in expected_columns if col not in df.columns]
        if missing_columns:
            print(f"âŒ Thiáº¿u cÃ¡c cá»™t: {missing_columns}")
            return
        
        # Chá»‰ giá»¯ cÃ¡c cá»™t cáº§n thiáº¿t
        df_v = df[expected_columns].copy()
        print(f"âœ… Filtered columns. Shape: {df_v.shape}")
        
        # Xá»­ lÃ½ dá»¯ liá»‡u
        df_v = df_v.dropna().reset_index(drop=True)
        print(f"âœ… Removed null values. Shape: {df_v.shape}")
        
        # Kiá»ƒm tra kiá»ƒu dá»¯ liá»‡u
        print(f"ğŸ“Š Data types:")
        for col in df_v.columns:
            print(f"  {col}: {df_v[col].dtype}")
        
        # Chuáº©n hÃ³a Ä‘Æ¡n vá»‹ vÃ  ItemCode
        print(f"ğŸ”„ Converting Unit and ItemCode...")
        df_v['Unit'] = df_v['Unit'].astype(str).str.lower()
        df_v['ItemCode'] = df_v['ItemCode'].astype(str).str.strip()
        
        print(f"ğŸ“Š Unit values: {df_v['Unit'].unique()}")
        print(f"ğŸ“Š ItemCode sample: {df_v['ItemCode'].head().tolist()}")
        
        # Lá»c theo Ä‘iá»u kiá»‡n: chá»‰ giá»¯ 'viÃªn' vÃ  ItemCode khÃ¡c 'VANCHUYEN'
        df_v_filtered = df_v[(df_v['Unit'] == 'viÃªn') & (df_v['ItemCode'] != 'VANCHUYEN')].copy()
        print(f"âœ… Filtered by unit and item code. Shape: {df_v_filtered.shape}")
        
        # Lá»c hÃ ng bÃ¡n (Quantity > 0)
        df_pos = df_v_filtered[df_v_filtered['Quantity'] > 0].copy()
        print(f"âœ… Filtered positive quantities. Shape: {df_pos.shape}")
        
        # Gá»™p dá»¯ liá»‡u theo ItemCode vÃ  DocDate
        print(f"ğŸ”„ Grouping by ItemCode and DocDate...")
        df_grouped = (
            df_pos.groupby(['ItemCode', 'DocDate'], as_index=False)
            .agg({'Quantity': 'sum'})
        )
        print(f"âœ… Grouped by ItemCode and DocDate. Shape: {df_grouped.shape}")
        
        # Sáº¯p xáº¿p theo thá»i gian
        df_grouped = df_grouped.sort_values('DocDate').reset_index(drop=True)
        
        # Äáº£m báº£o DocDate lÃ  datetime
        print(f"ğŸ”„ Checking DocDate type...")
        print(f"ğŸ“Š DocDate dtype: {df_grouped['DocDate'].dtype}")
        print(f"ğŸ“Š DocDate sample: {df_grouped['DocDate'].head()}")
        
        if not pd.api.types.is_datetime64_any_dtype(df_grouped['DocDate']):
            print(f"ğŸ”„ Converting DocDate to datetime...")
            df_grouped['DocDate'] = pd.to_datetime(df_grouped['DocDate'], errors='coerce')
            df_grouped = df_grouped.dropna(subset=['DocDate'])
        
        print(f"âœ… DocDate is datetime. Shape: {df_grouped.shape}")
        
        # Loáº¡i bá» sáº£n pháº©m bÃ¡n Ã­t ngÃ y
        print(f"ğŸ”„ Removing products with <= 5 days...")
        day_counts = df_grouped.groupby('ItemCode')['DocDate'].nunique()
        few_day_products = day_counts[day_counts <= 5].index
        df_grouped = df_grouped[~df_grouped['ItemCode'].isin(few_day_products)].copy()
        print(f"âœ… Removed products with <= 5 days. Shape: {df_grouped.shape}")
        
        # Táº¡o dá»¯ liá»‡u theo tuáº§n
        print(f"ğŸ”„ Creating weekly data...")
        df_grouped['week_start'] = df_grouped['DocDate'].dt.to_period('W').apply(lambda r: r.start_time)
        
        weekly_demand = (
            df_grouped
            .groupby(['ItemCode', 'week_start'], as_index=False)
            .agg({'Quantity': 'sum'})
        )
        
        weekly_demand.columns = ['ItemCode', 'Week', 'TotalQuantity']
        weekly_demand = weekly_demand.sort_values(by=['ItemCode', 'Week']).reset_index(drop=True)
        print(f"âœ… Created weekly demand data. Shape: {weekly_demand.shape}")
        
        # Táº¡o thá»‘ng kÃª
        stats = {
            "total_products": len(weekly_demand['ItemCode'].unique()),
            "total_weeks": len(weekly_demand['Week'].unique()),
            "total_records": len(weekly_demand),
            "date_range": {
                "start": weekly_demand['Week'].min().strftime('%Y-%m-%d'),
                "end": weekly_demand['Week'].max().strftime('%Y-%m-%d')
            }
        }
        
        print(f"âœ… Processing completed successfully!")
        print(f"ğŸ“Š Stats: {stats}")
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")

if __name__ == "__main__":
    debug_data_processing()
